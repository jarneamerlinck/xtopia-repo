{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gezichtsherkenning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages\n",
    "Use conda environment: *xtopia-video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Van statische image deepface analyse maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgpath = 'Images/Neutral Face.jpg'  #put the image where this file is located and put its name here\n",
    "image = cv2.imread(imgpath)\n",
    "\n",
    "analyze = DeepFace.analyze(image, actions = ['emotion'])  # analyseren van de image met de analyze functie van de deepface package\n",
    "\n",
    "print(analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"dominante emotie: {analyze['dominant_emotion']}\") # printen dominante emotie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# cv2.putText(image,\n",
    "#             analyze['dominant_emotion'],\n",
    "#             (0, 50),\n",
    "#             font, 1,\n",
    "#             (0,0,255),\n",
    "#             2,\n",
    "#             cv2.LINE_4);\n",
    "#\n",
    "# plt.imshow(cv2.cvtColor(image, cv2.COLOR_YCrCb2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Deepface analyse van Webcam input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX # font instellen voor emotie op webcam beeld te printen\n",
    "delay = 0   # timer om de deepface analyse maar op de zoveel keren van de while loop uit te laten voeren\n",
    "            # bv door maar op de 50 keer door de while te gaan een analyse maken, om geheugen te besparen\n",
    "\n",
    "\n",
    "face_cascade_name = cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml'  #getting a haarcascade xml file\n",
    "face_cascade = cv2.CascadeClassifier()  #processing it for our project\n",
    "if not face_cascade.load(cv2.samples.findFile(face_cascade_name)):  #adding a fallback event\n",
    "    print(\"Error loading xml file\")\n",
    "\n",
    "video = cv2.VideoCapture(0) # parameter 0 omdat we maar 1 camera hebben (1 webcam), indien bv. 2 camera's -> parameter 1, enz ...\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not video.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while video.isOpened():  #checking if are getting video feed and using it\n",
    "    ret,frame = video.read() #  ret is a Boolean value returned by the read function, and it indicates whether or not the frame was captured                                successfully. If the frame is captured correctly, it's stored in the variable frame.\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  #changing the video to grayscale to make the face analisis work properly\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "\n",
    "      cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 1)  # vierkant rond gezicht zetten + kleur\n",
    "\n",
    "    if delay % 10 == 0:    # voer analyse maar uit op de 50 keer door de while te gaan\n",
    "        #making a try and except condition in case of any errors\n",
    "        try:\n",
    "          analyze = DeepFace.analyze(frame, actions = ['emotion'])\n",
    "          result = analyze['dominant_emotion']\n",
    "        except:\n",
    "          result = \"no face\"\n",
    "          #print(\"no face\")\n",
    "\n",
    "    # emotie op webcam beeld afdrukken\n",
    "    cv2.putText(frame,\n",
    "                result,\n",
    "                (0, 50),\n",
    "                font, 1,\n",
    "                (0,0,255),\n",
    "                2,\n",
    "                cv2.LINE_4)\n",
    "\n",
    "    if(delay < 500):\n",
    "        delay+=1 # timer incrementeren\n",
    "    else:\n",
    "        delay = 0 # timer resetten, zodat deze niet te groot wordt\n",
    "\n",
    "    #this is the part where we display the output to the user\n",
    "    cv2.imshow('video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): # klik op 'q' toets op af te sluiten\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# In klassen (cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global delay # timer om de deepface analyse maar op de zoveel keren van de while loop uit te laten voeren\n",
    "            # bv door maar op de 50 keer door de while te gaan een analyse maken, om geheugen te besparen\n",
    "delay = 0\n",
    "\n",
    "face_cascade_name = cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml'  #getting a haarcascade xml file\n",
    "face_cascade = cv2.CascadeClassifier()  #processing it for our project\n",
    "\n",
    "\n",
    "def emotion_detection():\n",
    "\n",
    "    if not face_cascade.load(cv2.samples.findFile(face_cascade_name)):  #adding a fallback event\n",
    "        print(\"Error loading xml file\")\n",
    "\n",
    "    video = cv2.VideoCapture(0)  # parameter 0 omdat we maar 1 camera hebben (1 webcam), indien bv. 2 camera's -> parameter 1, enz ...\n",
    "\n",
    "    # Check if the webcam is opened correctly\n",
    "    if not video.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while video.isOpened():  #checking if are getting video feed and using it\n",
    "        isFrameCaptured, frame = video.read()  #  ret is a Boolean value returned by the read function, and it indicates whether or not the frame was captured successfully. If the frame is captured correctly, it's stored in the variable frame.\n",
    "\n",
    "        if not isFrameCaptured:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        detect_face(frame)\n",
    "        check_emotion_every_X_seconds(frame, delay)\n",
    "\n",
    "        #this is the part where we display the output to the user\n",
    "        cv2.imshow('video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):  # klik op 'q' toets op af te sluiten\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def check_emotion(frame):\n",
    "    #making a try and except condition in case of any errors\n",
    "    try:\n",
    "        analyze = DeepFace.analyze(frame, actions=['emotion'])\n",
    "        result = analyze['dominant_emotion']\n",
    "    except:\n",
    "        result = \"no face\"\n",
    "\n",
    "    return result\n",
    "\n",
    "def print_emotion_on_screen(frame, result):\n",
    "    # emotie op webcam beeld afdrukken\n",
    "    cv2.putText(frame,\n",
    "                result,\n",
    "                (0, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, # font instellen (Hershey Simplex)\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv2.LINE_4)\n",
    "\n",
    "def detect_face(frame):\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,\n",
    "                        cv2.COLOR_BGR2GRAY)  #changing the video to grayscale to make the face analisis work properly\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    for x, y, w, h in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 1)  # vierkant rond gezicht zetten + kleur\n",
    "\n",
    "def check_emotion_every_X_seconds(frame, timer):\n",
    "    if timer % 10 == 0:  # voer analyse maar uit op de 10 keer (1 sec) door de while te gaan\n",
    "        result = check_emotion(frame)\n",
    "    print_emotion_on_screen(frame, result)\n",
    "    if (timer < 500):\n",
    "        timer += 1  # timer incrementeren\n",
    "    else:\n",
    "        timer = 0  # timer resetten, zodat deze niet te groot wordt\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotion_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('xtopia-video')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b386342596285abf0179f7cbb8ac22c0f4993603227d13f3626e0042cd4e0b99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
